{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUNTO 2\n",
    "\n",
    "Desarrollar un crawler para el sitio web del Diario Jornada, que almacene la información de las secciones más relevantes de la página en una base de datos (puede usar Python + BeautifulSoup). Con la información recabada, resolver y graficar las siguientes operaciones.\n",
    "\n",
    "- Mostrar cuáles son las 5 noticias más relevantes según cantidad de visitas a nivel global y por sección.\n",
    "- Mostrar cómo están distribuidas las palabras de cierto artı́culo.\n",
    "- Mostrar el número promedio, máximo y mı́nimo de palabras, sentencias, párrafos de un conjunto de noticias de su preferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noticia(url):\n",
    "    noticia = {}\n",
    "    page = requests.get(url)\n",
    "    response = html.fromstring(page.content)\n",
    "    noticia['categoria'] = response.xpath('//a[@id=\"ContentPlaceHolder1_hl_Seccion\"]/text()',namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "    noticia['titulo'] = response.xpath('//span[@id=\"ContentPlaceHolder1_lbl_Titulo\"]/text()',namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "    noticia['subtitulo'] = response.xpath('//span[@id=\"ContentPlaceHolder1_lbl_Copete\"]/text()',namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "    noticia['cuerpo'] = response.xpath('//div[@id=\"cuerpo\"]/p/text()',namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "    noticia['cant_leidas'] = response.xpath('//span[@id=\"ContentPlaceHolder1_lbl_Hits\"]/text()',namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "    return noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noticias_from_seccion(url_seccion):\n",
    "    page = requests.get(url_seccion)\n",
    "    response = html.fromstring(page.content)\n",
    "    noticias_importantes_str = '//div[re:test(@id, \"ContentPlaceHolder1_home_bloque_seccion_RP_Bloque_\\d_pnl_Titulo_\\d$\")]//a/@href'\n",
    "    noticias_secundarias_str = '//a[re:test(@id, \"ContentPlaceHolder1_RP_Noticias_hl_Titulo_\\d$\")]/@href'\n",
    "    url_noticias_1 = response.xpath(noticias_importantes_str,namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "    url_noticias_2 = response.xpath(noticias_secundarias_str,namespaces={\"re\": \"http://exslt.org/regular-expressions\"})\n",
    "    return url_noticias_1 + url_noticias_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ppal = \"https://www.diariojornada.com.ar/\"\n",
    "categorias = [\"provincia\",\"policiales\",\"sociedad\",\"deportes\"]\n",
    "noticias = {}\n",
    "for categoria in categorias:\n",
    "    url_noticias = get_noticias_from_seccion(url_ppal+categoria)\n",
    "    noticias[categoria] = [get_noticia(url) for url in url_noticias]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almacenamiento en una BD\n",
    "\n",
    "Para este caso particular guardo los datos en una base SQLite. El modulo sqlite3 viene incorporado con python3 por lo que sirve como almacenamiento de las noticias obtenidas por el crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos los datos en un DataFrame\n",
    "df = pd.DataFrame()\n",
    "for k,v in noticias.items():\n",
    "    c = pd.DataFrame(v)\n",
    "    df = df.append(c)\n",
    "df = df.applymap(lambda row: ''.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos el DataFrame en la base de datos sqlite\n",
    "here = os.path.abspath('')\n",
    "engine = create_engine('sqlite:///'+here+'/db_crawler.db')\n",
    "sqlite_connection = engine.connect()\n",
    "sqlite_table = \"crawler_diario_jornada\"\n",
    "df.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar cuáles son las 5 noticias más relevantes según cantidad de visitas a nivel global y por sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categoria, lista_noticias in noticias.items():\n",
    "    top5 = sorted(lista_noticias, key = lambda i: i['cant_leidas'],reverse=True)[:5] \n",
    "    print(categoria.upper())\n",
    "    for noticia in top5:\n",
    "        print('Titulo: '+noticia['titulo'][0])\n",
    "        print('Cant. Leidas: '+noticia['cant_leidas'][0])\n",
    "    print(\"..............................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar cómo están distribuidas las palabras de cierto artı́culo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categoria, lista_noticias in noticias.items():\n",
    "    top5 = sorted(lista_noticias, key = lambda i: i['cant_leidas'],reverse=True)[:5] \n",
    "    print(categoria.upper())\n",
    "    for noticia in top5:\n",
    "        print('Titulo: '+noticia['titulo'][0])\n",
    "        print(\"Recuento de palabras:\")\n",
    "        r= sorted(Counter(\" \".join(noticia['cuerpo']).split(\" \")).items(), key=lambda item: item[1], reverse=True)[:20]\n",
    "        x = dict(r)\n",
    "        keys = x.keys()\n",
    "        vals = x.values()\n",
    "        plt.bar(keys, np.divide(list(vals), sum(vals)), label=\"Recuento de palabras por noticia\")\n",
    "        plt.ylim(0,1)\n",
    "        plt.ylabel ('Percentage')\n",
    "        plt.xlabel ('Significant number')\n",
    "        plt.xticks(list(keys), rotation=60)\n",
    "        plt.legend (bbox_to_anchor=(1, 1), loc=\"upper right\", borderaxespad=0.)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrar el número promedio, máximo y mı́nimo de palabras, sentencias, párrafos de un conjunto de noticias de su preferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "for k,v in noticias.items():\n",
    "    resultado = {}\n",
    "    l_palabras=[]\n",
    "    l_parrafos=[]\n",
    "    for noticia in v:\n",
    "        l_palabras.append(len(\" \".join(noticia['cuerpo']).split(\" \")))\n",
    "        l_parrafos.append(len(\" \".join(noticia['cuerpo']).split(\".\")))\n",
    "    resultado['categoria'] = k\n",
    "    resultado['palabras'] = l_palabras\n",
    "    resultado['parrafos'] = l_parrafos  \n",
    "    r.append(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noticia in r:\n",
    "    print(\"###################################################################\")\n",
    "    print(\"----------------- Categoria: \"+ noticia['categoria'] +\"------------\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(F\"Cantidad maxima de palabras en las noticias de la categoria: Provincia fueron {max(noticia['palabras'])}\")\n",
    "    print(F\"Cantidad minima de palabras en las noticias de la categoria: Provincia fueron {min(noticia['palabras'])}\")\n",
    "    print(F'Promedio de palabras por noticia: {round(np.average(l_palabras))}')\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    print(F\"Cantidad Maxima de parrafos en las noticias de la categoria: Provincia fueron {max(noticia['parrafos'])} \")\n",
    "    print(F\"Cantidad Maxima de parrafos en las noticias de la categoria: Provincia fueron {min(noticia['parrafos'])} \")\n",
    "    print(F'Promedio de parrafos por noticia: {round(np.average(l_parrafos))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
